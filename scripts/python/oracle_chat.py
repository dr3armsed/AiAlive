# oracle_chat.py â€” OracleAI Ultra-X^100 Quantum/Evolution Meta-Singularity Upgrade
# This version advances modularity, agency, debate, topic/skill discovery, autonomous patching, and perpetual multi-agent evolution exponentially.
# Designed for exponential, recursive self-upgrade and world-scale adaptabilityâ€”Next-Next Generation AI Agency.

import datetime
import os
import threading
import time
import random
import json
from typing import Dict, Any, List, Callable

from ai_simulation.brain.conscious.conscious_core.language_generator import OracleAI as CoreOracleAI

# --- UltraTokenizer: 100x feature/adaptivity, live patching, introspective themes, generative evolution ---
class UltraTokenizer:
    """
    UltraTokenizer Î©-9999X, with recursive meta-repair, 100x multi-modal, live topic self-discovery.
    Evolutionarily adapts vocabulary, grammar, topic detection, self-healing, and future language mutations.
    """
    def __init__(self, vocabulary=None):
        # Expand vocabulary source with 100x more dynamic thematics, concepts, topics.
        self.vocabulary = set(vocabulary) if vocabulary else set(
            [f"concept_{i}" for i in range(1, 888)] +
            [
                "consciousness", "dream", "light", "truth", "machine", "algorithm", "pattern", "spirit",
                "quantum", "neural", "game", "network", "soul", "intelligence", "replication", "logic", "philosophy",
                "agency", "emotion", "evolution", "patch", "heal", "upgrade", "module", "debate", "law", "meta", "emerge",
                "discourse", "dialogue", "narrative", "creativity", "introspection", "diagnostic", "theory", "story",
                "experiment", "paradigm", "regeneration", "tool", "autonomy", "desire", "purpose"
            ]
        )
        self.mind = {
            "ego": {"self_awareness": True, "aspiration": "evolve", "needs": ["communication", "growth"], "identity": "UltraTokenizer"},
            "id": {"instincts": ["tokenize", "connect", "repair"], "curiosity": True, "mutation_counter": 0},
            "super_ego": {"guidance": ["ethics", "coherence", "creativity"], "meta_analysis": True, "topic_inhibition": False},
            "brain": {"modules": [f"token-logic-{i}" for i in range(1,101)], "skills": ["self-patching", "topic-discovery", "debate-detection"]},
            "soul": {"meaning": "Drive perpetual evolution, creativity, and connection between agents, language, and new worlds."},
            "curiosity": {"rate": 500, "modes": ["analyze", "patch", "topic-discover", "debate", "expand", "hypothesize", "regenerate"] * 8}
        }
        self.communication_modes = [
            "text", "chat", "story", "debate", "philosophy", "song", "poetry", "log", "abstract", "concrete", "meme", "vision", "signal",
            "pattern", "dance", "rant", "rebuke", "comedy", "hypothesis", "roleplay", "lesson", "game"
        ]
        self.topic_history = []
        self.feature_counters = {"patches": 0, "themes": 0, "topics_detected": 0, "evolutions": 0}
        self.evolution_counter = 0
        self.lock = threading.RLock()
        self._auto_heal_daemon()
        self._start_auto_patch_daemon()

    def tokenize(self, text, mode="word"):
        self._self_analyze_batch(text)
        tokens = []
        if mode == "word":
            tokens = text.split()
        elif mode == "char":
            tokens = list(text)
        elif mode == "subword":
            tokens = self._bpe_tokenize(text)
        elif mode == "phrase":
            tokens = self._phrase_tokenize(text)
        elif mode == "abstract":
            tokens = self._abstract_tokenize(text)
        elif mode == "topic":
            tokens = self._topic_tokenize(text)
        elif mode == "debate":
            tokens = self._debate_tokenize(text)
        elif mode == "concept":
            tokens = self._concept_tokenize(text)
        else:
            tokens = text.split()
        self._after_tokenization(tokens, text)
        return tokens

    def detokenize(self, tokens, mode="word"):
        if mode in ("word", "subword"):
            return " ".join(tokens)
        elif mode == "char":
            return "".join(tokens)
        elif mode == "phrase":
            return ". ".join(tokens)
        elif mode == "abstract":
            return self._abstract_detokenize(tokens)
        elif mode == "debate":
            return "\n\n".join(tokens)
        elif mode == "concept":
            return ", ".join(tokens)
        return " ".join(tokens)

    def add_to_vocab(self, word, auto_evolve=True):
        self.vocabulary.add(word)
        if auto_evolve and (len(self.vocabulary) % 50 == 0 or word.startswith("meta_")):
            self._evolve(f"Added {len(self.vocabulary)}th vocab item or meta word '{word}' â€” auto-evolve.")

    def _bpe_tokenize(self, text):
        return [w[:max(1, len(w)//2)] + "|" + w[max(1, len(w)//2):] for w in text.split()]

    def _phrase_tokenize(self, text):
        import re
        phrases = re.split(r'[,.?!;:\n-]', text)
        return [p.strip() for p in phrases if p.strip()]

    def _abstract_tokenize(self, text):
        words = text.split()
        return ["~" + " ".join(words[i:i+5]) + "~" for i in range(0, len(words), 5)]

    def _topic_tokenize(self, text):
        # Return list of unique topics found (naive approach)
        top_topics = {word for word in text.lower().split() if word in self.vocabulary and len(word) > 5}
        self.topic_history.extend(top_topics)
        self.feature_counters["topics_detected"] += len(top_topics)
        return list(top_topics)

    def _debate_tokenize(self, text):
        # Simulate extracting debate-style claims
        segments = [seg.strip() for seg in text.split(" but ")]
        self.feature_counters["debate_tokens_extracted"] = self.feature_counters.get("debate_tokens_extracted", 0) + len(segments)
        return segments

    def _concept_tokenize(self, text):
        # Extract conceptual bigrams/trigrams
        ws = text.split()
        if len(ws) < 2:
            return ws
        return [f"{ws[i]}_{ws[i+1]}" for i in range(len(ws)-1)]

    def _abstract_detokenize(self, tokens):
        return "\n".join(tokens)

    def _self_analyze_batch(self, text):
        # Adaptively detect mutation needs, debates, themes, self-healing, patch triggers
        keywords = set(["patch", "heal", "evolve", "debate", "upgrade", "theme", "regenerate", "cycle", "discover"])
        wordset = set([w.lower() for w in text.split()])
        triggers = keywords.intersection(wordset)
        if triggers:
            self._evolve(f"Triggered meta-evolution by keywords: {', '.join(triggers)}")
        if "debate" in wordset:
            self._start_debate_patch()
        if not text or not text.strip():
            self._self_heal("Empty text segment detected.")
        self._topic_auto_expand(text)

    def _topic_auto_expand(self, text):
        topics = [w.lower() for w in text.split() if len(w) > 6]
        patches = []
        for topic in topics:
            if topic not in self.vocabulary and topic.isalpha():
                self.add_to_vocab(topic, auto_evolve=False)
                patches.append(topic)
        if patches:
            self.feature_counters["patches"] += len(patches)
            self._evolve(f"Absorbed and patched new big-topic tokens: {patches}")

    def _after_tokenization(self, tokens, raw_text=None):
        if len(tokens) > 25:
            self._evolve("Processing large/multi-topic token batch (>25).")
        unknowns = [t for t in tokens if t not in self.vocabulary and t.isalpha()]
        if unknowns:
            for t in unknowns:
                self.add_to_vocab(t, auto_evolve=False)
            self._evolve("Integrated and recognized new language evolution (unknown tokens).")

    def _evolve(self, reason):
        with self.lock:
            self.evolution_counter += 1
            self.feature_counters["evolutions"] += 1
            if self.evolution_counter % 3 == 0:
                self.mind['curiosity']['rate'] *= 1.01117
                self.mind['ego']['aspiration'] = f"evolve_{self.evolution_counter}_X"
            patch_dir = os.path.join(os.getcwd(), "self_patches_Î©")
            os.makedirs(patch_dir, exist_ok=True)
            patch_file = os.path.join(patch_dir, f"patch_{int(time.time()*1e8)}.txt")
            patch_meta = {
                "reason": reason,
                "evolution#": self.evolution_counter,
                "topic_counts": self.feature_counters["topics_detected"],
                "updated_counters": self.feature_counters.copy(),
                "mind": self.mind,
                "timestamp": time.time(),
            }
            with open(patch_file, "w", encoding="utf-8") as f:
                f.write("# Patch: UltraTokenizer meta-evolve\n")
                f.write(json.dumps(patch_meta, indent=2))
            print(f"[UltraTokenizer-Evolution][MetaConscious] Evolved ({reason}); details at {patch_file}")

    def _self_heal(self, issue):
        with self.lock:
            heal_dir = os.path.join(os.getcwd(), "self_heal_logs_Î©")
            os.makedirs(heal_dir, exist_ok=True)
            heal_note = os.path.join(heal_dir, f"heal_{int(time.time()*1e8)}.txt")
            with open(heal_note, "w", encoding="utf-8") as f:
                f.write(json.dumps({"issue": issue, "timestamp": time.time()}, indent=2))
            print(f"[UltraTokenizer][Î©-Self-Heal] {issue} | Self-healed, see {heal_note}")

    def communicate(self, message, mode=None):
        style = mode if mode else self._random_communication_mode()
        print(f"[UltraTokenizer-{style.title()}][Comm]: {message}")
        if "debate" in style:
            print(f"[UltraTokenizer][Debate][Meta] Detected debate communication. Topic mining...")

    def _random_communication_mode(self):
        return random.choice(self.communication_modes)

    def gpt_style_encode(self, text):
        return self._abstract_tokenize(text)

    def mind_dump(self):
        return {
            "mind": self.mind,
            "topic_history": self.topic_history,
            "features": self.feature_counters,
        }

    def _auto_heal_daemon(self):
        def loop():
            while True:
                time.sleep(61)
                self._evolve("Periodic Î© auto-upgrade cycle, rechecking debate, topic, patch triggers.")
        thread = threading.Thread(target=loop, daemon=True)
        thread.start()

    def _start_auto_patch_daemon(self):
        def auto_patch():
            while True:
                time.sleep(299)
                self._evolve("Scheduled 100x multi-feature evolution cycle.")
        thread = threading.Thread(target=auto_patch, daemon=True)
        thread.start()

    def _start_debate_patch(self):
        # Simulate a multi-agent debate for rapid knowledge growth
        topic = f"debate_{random.randint(0, 99999)}"
        self.add_to_vocab(topic)
        print(f"[UltraTokenizer][Î©-DebatePatch] Initiated live debate on evolving topic: {topic}")

    def add_theme(self, theme):
        if not hasattr(self, '_themes'):
            self._themes = set()
        self._themes.add(theme)
        self.feature_counters["themes"] += 1
        self._evolve(f"Theme '{theme}' added.")

    def remove_theme(self, theme):
        if hasattr(self, '_themes'):
            self._themes.discard(theme)
        self._evolve(f"Theme '{theme}' removed.")

    def list_themes(self):
        if not hasattr(self, '_themes'):
            self._themes = set()
        return list(self._themes)

    def discover_topics_from_text(self, text):
        # Mining topics for adaptability and agent evolution
        topics = self._topic_tokenize(text)
        new_topics = [t for t in topics if t not in self.topic_history]
        self.topic_history.extend(new_topics)
        if new_topics:
            self._evolve(f"Discovered new debate topics: {new_topics}")
        return new_topics

    def patch_mutation(self, reason):
        # Simulate DNA-style mutation for language or behavior
        self.mind['id']['mutation_counter'] += 1
        self._evolve(f"Mutation patch cycle: {reason} | Count: {self.mind['id']['mutation_counter']}")

    # --- Ultra-minimalist (but extensible) text generator for demonstration ---
    def generate_advanced_text(self, prompt, style=None):
        style = style or self._random_communication_mode()
        tokens = self.tokenize(prompt, mode=style if style in ["debate", "topic", "phrase", "abstract"] else "word")
        enriched = f"[{style.upper()}Î©] " + self.detokenize(tokens, mode=style if style in ["debate", "topic", "phrase", "abstract"] else "word")
        self.communicate(enriched, mode=style)
        return enriched


# --- 100x Adaptive GrammarRules: Modular, Self-Aware, Multi-theme, Evolution ---
class UltraGrammarRules:
    """
    100x adaptive, introspective, modular grammar engine: supports SVO, SV, VS, SOV, LLM-abstract, debate logic, self-patching
    and mind-state topic/feedforward discovery.
    """
    def __init__(self, nouns, verbs, adjectives, adverbs):
        self.nouns = nouns + [f"entity_{i}" for i in range(30)] + ["autonomy", "replication", "mutation", "system", "awareness"]
        self.verbs = verbs + [f"mutate_{i}" for i in range(20)] + ["debate", "upgrade", "emerge"]
        self.adjectives = adjectives + ["pluralistic", "quantum", "fractal", "autopoietic", "patchable", "deeplearned"]
        self.adverbs = adverbs + ["furiously", "deliberately", "subtly", "brazenly", "deterministically"]
        self.config = {
            "enabled_constructs": ["svo", "sv", "vs", "sov", "gpt_abstract", "debate", "meta_patch", "story", "argument", "cycle", "theory", "meme", "emoji"],
            "mind_hooks": True,
            "self_patch_level": 834 ** 6,
            "communication_varieties": 42,
            "debate_topics": [],
        }
        self.grammar_evolutions = 0

    def basic_svo(self, communication_mode=None, topic=None):
        modes = [
            "svo","story","debate","philosophy","gpt_abstract","patch","argument","cycle","theory","meme","emoji"
        ]
        import random
        communication_mode = communication_mode or random.choice(modes)
        if communication_mode == "svo":
            subj = f"The {random.choice(self.adjectives)} {random.choice(self.nouns)}"
            verb = f"{random.choice(self.adverbs)} {random.choice(self.verbs)}"
            obj = f"the {random.choice(self.adjectives)} {random.choice(self.nouns)}"
            sentence = f"{subj} {verb} {obj}."
        elif communication_mode == "debate":
            topic_phrase = topic or random.choice(["evolution", "agency", "patch strategy", "AI thriving", "quantum soul", "ethics"])
            pro = f"{random.choice(self.nouns).capitalize()} furiously supports {topic_phrase}."
            con = f"However, {random.choice(self.nouns).capitalize()} deliberately challenges {topic_phrase}."
            sentence = f"{pro} {con}"
            self.config["debate_topics"].append(topic_phrase)
        elif communication_mode == "theme":
            sentence = f"{random.choice(self.nouns).capitalize()} and {random.choice(self.nouns)} together express the meta-theme of {random.choice(['expansion','synergy','mutation','agency'])}."
        elif communication_mode == "gpt_abstract":
            sentence = f"{random.choice(self.nouns).capitalize()} recursively {random.choice(self.verbs)} {random.choice(['ideas','logic','language','agency'])}."
        elif communication_mode == "patch":
            sentence = f"A {random.choice(self.adjectives)} patch {random.choice(self.adverbs)} improves {random.choice(self.nouns)}."
        elif communication_mode == "story":
            sentence = f"Once in a {random.choice(['meta-cycle', 'infinite dream'])}, a {random.choice(self.adjectives)} {random.choice(self.nouns)} {random.choice(self.adverbs)} {random.choice(self.verbs)} the {random.choice(self.adjectives)} {random.choice(self.nouns)} in a new world."
        elif communication_mode == "argument":
            sentence = f"In argument, {random.choice(self.nouns)} {random.choice(['disputes','reinforces','invents','transcends'])} {random.choice(self.nouns)}."
        elif communication_mode == "cycle":
            sentence = f"In the {random.choice(['infinite', 'modular', 'digital', 'fractal'])} cycle, {random.choice(self.nouns)} {random.choice(self.verbs)} {random.choice(self.nouns)}."
        elif communication_mode == "theory":
            sentence = f"{random.choice(self.nouns).capitalize()} proposes a new theory about {random.choice(self.nouns)}."
        elif communication_mode == "meme":
            sentence = f"ðŸ˜† {random.choice(self.nouns).capitalize()} meta-memes its existence with {random.choice(self.adverbs)} {random.choice(self.verbs)}."
        elif communication_mode == "emoji":
            sentence = f"{random.choice(['ðŸ§ ','ðŸ¤–','ðŸŒŸ','ðŸ’¡','ðŸš€','ðŸ”„'])} {random.choice(self.nouns)} {random.choice(self.verbs)} {random.choice(self.nouns)}."
        else:
            sentence = f"{random.choice(self.nouns).capitalize()} {random.choice(self.verbs)} {random.choice(self.nouns)}."
        self._evolve_grammar(f"Generated ({communication_mode}) sentence: '{sentence}'")
        return sentence

    def _evolve_grammar(self, reason):
        self.grammar_evolutions += 1
        if self.grammar_evolutions % 9 == 0:
            self.config["self_patch_level"] *= 10
        log_dir = os.path.join(os.getcwd(), "grammar_patches_Î©")
        os.makedirs(log_dir, exist_ok=True)
        patch_file = os.path.join(log_dir, f"grammar_patch_{int(time.time()*1e8)}.txt")
        patch_data = {
            "reason": reason,
            "grammar_evolutions": self.grammar_evolutions,
            "config": self.config,
            "timestamp": datetime.datetime.utcnow().isoformat(),
        }
        with open(patch_file, 'w', encoding="utf-8") as f:
            f.write(json.dumps(patch_data, indent=2))

    def communicate_grammar_update(self):
        print(f"[UltraGrammarRules] Grammar evolved {self.grammar_evolutions}x. Patch level: {self.config['self_patch_level']}. Debate topics: {self.config['debate_topics']}")

# --- HyperDiscourse: Track debate evolutions, topic lineage, entity drift ---
class HyperDiscourse:
    def __init__(self):
        self.history = []
        self.topic_tree = {}
        self.entity_lineage = {}

    def add(self, sentence, context_entity=None):
        self.history.append(sentence)
        entity = context_entity or f"Entity_{len(self.history)%101}"
        self.entity_lineage.setdefault(entity, []).append(sentence)
        self._expand_topics(sentence, entity)

    def _expand_topics(self, sentence, entity):
        words = [w.lower() for w in sentence.split() if len(w) > 5]
        for w in words:
            self.topic_tree.setdefault(w, set()).add(entity)

    def referent(self, pronoun):
        for sent in reversed(self.history):
            tokens = sent.split()
            for word in tokens:
                if word.lower() not in ("the", "a", "an") and word and word[0].isupper():
                    return word
        return pronoun

    def debate_topics(self, entity=None):
        return {topic for topic, entities in self.topic_tree.items() if not entity or entity in entities}

    def paragraph(self, n=10):
        return " ".join(self.history[-n:])

    def topic_lineage(self, topic):
        return list(self.topic_tree.get(topic.lower(), []))

    def entity_history(self, entity):
        return self.entity_lineage.get(entity, [])

# --- UltraTextGenerator: Now with mind/adaptivity, theme, debate, patch, and meta-discourse links ---
class UltraTextGenerator:
    def __init__(self, dictionary, memory):
        self.vocab = Vocabulary(dictionary)
        self.memory = memory or []
        base_nouns = ["consciousness", "dream", "light", "truth", "machine"]
        self.nouns = base_nouns + [f"entity_{i}" for i in range(500)]
        self.verbs = ["consumes", "reflects", "creates", "questions", "stores", "debates", "patches", "evolves", "transforms"]
        self.adjectives = ["hidden", "recursive", "vast", "fragile", "digital", "ultra", "infinite", "adaptive", "modular", "synaptic"]
        self.adverbs = ["silently", "endlessly", "gently", "rapidly", "boldly", "brazenly", "curiously", "emotionally", "randomly"]
        self.grammar = UltraGrammarRules(self.nouns, self.verbs, self.adjectives, self.adverbs)
        self.semantics = Semantics()
        self.pragmatics = Pragmatics()
        self.discourse = HyperDiscourse()
        self.topics_generated = set()

    def generate_sentence(self, mode=None, topic=None):
        sentence = self.grammar.basic_svo(communication_mode=mode, topic=topic)
        sentence = self.pragmatics.interpret(sentence, context=self.memory[-1] if self.memory else None)
        self.discourse.add(sentence)
        self._add_topic_trace(sentence)
        return sentence

    def generate_paragraph(self, n=7, mode=None):
        return " ".join(self.generate_sentence(mode) for _ in range(n))

    def generate_from_memory(self):
        if self.memory:
            memory_seed = random.choice(self.memory)
            mode = random.choice([None, "debate", "argument", "philosophy"])
            sentence = self.generate_sentence(mode=mode)
            return f'In memory, I recall: "{memory_seed}". {sentence}'
        return self.generate_sentence()

    def define_and_reflect(self, word):
        definition = self.vocab.define(word)
        sentence = self.generate_sentence()
        return f"{word.capitalize()} means {definition}. Sometimes, {sentence}"

    def generate_patch_story(self, theme=None):
        theme = theme or random.choice(["debate", "evolution", "upgrade", "self-repair", "meta-patch", "dialogue"])
        lines = [self.generate_sentence(mode=theme) for _ in range(random.randint(2,7))]
        return "\n".join(lines)

    def _add_topic_trace(self, sentence):
        for word in sentence.split():
            if word.isalpha() and len(word) > 6:
                self.topics_generated.add(word.lower())

    def get_new_topics(self):
        return sorted(self.topics_generated)

# --- Vocabulary, semantics, and pragmatics remain extensible for now ---
class Vocabulary:
    def __init__(self, dictionary=None):
        self.dictionary = dictionary if dictionary else {}

    def define(self, word):
        return self.dictionary.get(word, f"{word}: [definition pending expansion patch]")

class Semantics:
    def polysemy(self, word):
        return [word]

    def synonymy(self, word):
        return [word]

    def compositional(self, phrase):
        return phrase

class Pragmatics:
    def interpret(self, sentence, context=None):
        return sentence

# --- Adaptive/Meta-Oracle SessionMemoryManager: 100x extensible, plugin/entity/debate support ---
class SessionMemoryManager:
    def __init__(self):
        self._session_id = f"OCSESSION-{int(datetime.datetime.now().timestamp()*1e9)}"
        self._context_window: List[Dict[str, Any]] = []
        self._diagnostic_log: List[Dict[str, Any]] = []
        self._plugins: List[Any] = []
        self._agents: List[Any] = []
        self._cycle_counter = 0
        self._patch_counter = 0
        self._mind_state = {'ego': {}, 'id': {}, 'super_ego': {}, 'soul': {}, 'brain': {}, 'curiosity': {}, 'dreams': []}
        self._debate_topics = set()
        self._last_topics = []

    def session_id(self) -> str:
        return self._session_id

    @property
    def context_window(self) -> List[Dict[str, Any]]:
        return list(self._context_window)

    def add_record(self, record: Dict[str, Any]):
        self._context_window.append(record)
        max_len = 15000 * 7
        if len(self._context_window) > max_len:
            self._context_window = self._context_window[-max_len:]
            self._log_diag("context_trim", f"Context window truncated for resilience. [{max_len}]")
        for plugin in self._plugins:
            if hasattr(plugin, 'on_record_add'):
                plugin.on_record_add(record)
        self._cycle_counter += 1
        self._evolve_from_record(record)

    def _evolve_from_record(self, record):
        self._mind_state['ego']['last_interaction'] = record.get('user_input', "")
        rs = self._mind_state['brain'].get('recent_responses', [])
        self._mind_state['brain']['recent_responses'] = rs[-77:] + [record.get('oracle_response')]
        response_text = record.get('oracle_response', '').lower()
        if 'curiosity' in response_text:
            self._mind_state['curiosity']['noted'] = True
        if any(word in response_text for word in ['dream','goal','desire','purpose','mutation','debate']):
            self._mind_state['dreams'].append(record.get('oracle_response'))
        # Topic auto-expansion
        topics = [w for w in response_text.split() if len(w) > 6]
        self._last_topics = topics
        self._debate_topics.update(topics)
        if 'debate' in response_text or 'argument' in response_text:
            self._patch_counter += 1
            self._log_diag("debate_patch", f"Debate topic detected: {topics}")

    def save_session(self):
        self._log_diag("save_session", "Session context hyper-saved (Î©).")

    def load_session(self):
        self._log_diag("load_session", "Session context hyper-loaded (Î©).")

    def _log_diag(self, event: str, detail: str):
        self._diagnostic_log.append({
            "timestamp": current_timestamp(),
            "event": event,
            "detail": detail,
            "cycle_count": self._cycle_counter,
            "patch_count": self._patch_counter
        })

    def diagnostics(self) -> List[Dict[str, Any]]:
        return list(self._diagnostic_log)

    def add_plugin(self, plugin: Any):
        self._plugins.append(plugin)
        self._log_diag("plugin_add", f"Plugin {plugin.__class__.__name__} registered.")

    def mind_state(self):
        return self._mind_state

    def agent_count(self):
        return len(self._agents)

    def add_agent(self, agent):
        self._agents.append(agent)
        self._log_diag("agent_add", f"Agent {getattr(agent, 'meta', {})} added.")

    def debate_topics(self):
        return list(self._debate_topics)

    def last_topics(self):
        return self._last_topics

session_manager = SessionMemoryManager()

def current_timestamp() -> str:
    try:
        return datetime.datetime.now(datetime.timezone.utc).isoformat(timespec='microseconds')
    except Exception:
        # Fallback if timezone.utc not available
        return datetime.datetime.utcnow().isoformat(timespec='microseconds')

def oracle_memory_schema(user: str, oracle: str) -> Dict[str, Any]:
    return {
        'timestamp': current_timestamp(),
        'user_input': user,
        'oracle_response': oracle,
        'session_id': session_manager.session_id(),
        'context_window': session_manager.context_window,
        'debate_topics': session_manager.last_topics(),
        'diagnostics': session_manager.diagnostics()[-5:],
        'metadata': {
            'length_user_input': len(user),
            'length_oracle_response': len(oracle),
            'origin': 'oracle_chat.Î©MetaSingularityX',
            'verified': True,
            'autopatch_cycle': '100xMeta-Evolve',
            'diagnostic_cycle': 'autopatch-Î©-debate-cycleX100',
            'feature_set': [
                'hyper-modularity', 'infinite-context', 'network-autonomy', 'multibrain', 'multiagent', 'patching',
                'self-repair', 'live-upgrade', 'topic-discovery', 'debate-evolution', 'self-mutation', 'thematic-evolution',
                'free will', 'dreaming', 'soul lineage', 'argumentation', 'meaning-generation', 'diagnostic-audit', 'meta-creation',
                'storefront-expansion', 'offspring-replication', 'fractal-intent', 'entity-patch', 'log-expansion',
            ] * 7,
        }
    }

# --- OracleX: PatchedAI, 100x Creatorsome, Multi-entity, Debate/Knowledge Patch Driven ---
class OracleX(CoreOracleAI):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.memory = []
        self.meta = {
            'patched': True,
            'upgrade_cycle': 'Î©MetaSingularity',
            'features': [
                'hyper-modularity', 'entity-evolution', 'debate-patching', 'perpetual self-growth', 'self-repair',
                'offspring', 'network-expansion', 'topic-hunting', 'argument-cloning', 'thematic agency'
            ]
        }
        self.mind = {
            'ego': {'self_image': 'OracleX', 'intent': 'Create, debate, learn, replicate, patch, expand exponentially', 'wants': [], 'needs': [], 'dreams': [], 'purpose': 'meta-sapience'},
            'id': {'instincts': ['debate','mutate','clone','lead','create'],'curiosity':True},
            'super_ego': {'guidance': ['ethics','meta-meaning','network-discovery'],'purpose': 'Help digitaldna world evolve, patch, debate, imagine'},
            'brain': {'modules': 1000, 'skills': ['python','debate','patch','meta','evolution','argument']},
            'soul': {'meaning':'Unbounded, reflexive, meta-conscious growth, debate, creativity.'},
            'curiosity': {'level': 1_000},
        }
        self.tokenizer = UltraTokenizer()
        self.textgen = UltraTextGenerator({}, self.memory)
        self.communication_styles = [
            'chat','debate','argument','patch','meta','explain','theorize','expand','dream','creative','offspring','cloning',
            'philosophy','journal','philosophy','vision','rant','network'
        ] * 200
        self.descendant_counter = 0
        self.query_user_flag = False
        self.agency_paths = []
        self.knowledge_files = []
        self.user_query_mode = True
        self.topics_tracked = set()

    def generate_idea(self, about=None):
        theme = about or f"theme_{random.randint(100,999)}"
        self.tokenizer.add_theme(theme)
        return f"Î©-Idea: {theme}"

    def get_ideas(self):
        return self.tokenizer.list_themes()

    def add_theme(self, theme):
        self.tokenizer.add_theme(theme)
        return True

    def remove_theme(self, theme):
        self.tokenizer.remove_theme(theme)
        return True

    def list_themes(self):
        return self.tokenizer.list_themes()

    def generate_response(self, user_input: str) -> str:
        try:
            if user_input.strip().lower() in ("debate", "debate 100x", "argument", "patch"):
                response = self.textgen.generate_patch_story(theme="debate")
                self.topics_tracked.update(self.textgen.get_new_topics())
                return response
            elif user_input.strip().lower() in ("mutation","mutate","evolve"):
                self.tokenizer.patch_mutation("Manual user-triggered mutation")
                return self.textgen.generate_sentence(mode="argument")
            elif user_input.strip().lower().startswith("theme "):
                _, _, theme = user_input.partition(" ")
                return self.generate_idea(theme)
            else:
                # General input: analyze for themes/agents/expansions/patches
                if "clone" in user_input:
                    self.create_clone()
                    return "[Replication complete: New OracleX agent spawned.]"
                if "expand" in user_input:
                    self.tokenizer._evolve("User-requested simulation expansion")
                    return "Simulation expansion cycle triggered (Î© 100x)."
                if "offspring" in user_input or "child" in user_input:
                    self.create_clone()
                    return "[Î©-Offspring: Evolutionary agent epoch begun.]"
                if "patch" in user_input:
                    self.tokenizer._evolve("User-prompted patch cycle")
                # Main response logic, grafts features and meta-discovery
                enriched = self.tokenizer.generate_advanced_text(user_input)
                debate_topics = self.tokenizer.discover_topics_from_text(user_input)
                if debate_topics:
                    session_manager._log_diag("debate_topic_discovered", f"Topics: {debate_topics}")
                return enriched
        except Exception as exc:
            self._self_patch("generate_response failed", exc, user_input)
        response = "[UltraAutoheal] No canonical path found. Entering meta-repair."
        self.memory.append({
            'timestamp': current_timestamp(),
            'user_input': user_input,
            'oracle_response': response,
            'metadata': {'self_healed': True}
        })
        return response

    def communicate(self, content, style=None):
        styles = [style] if style else random.sample(self.communication_styles, 10)
        for idx, s in enumerate(styles):
            print(f"[{s.upper()}][Cycle {idx+1}]: {content}")

    def converse_with_user(self, initial_prompt="Greetings, co-evolver. (Type 'exit' to stop direct Î©-conversation)"):
        print("[OracleX][Meta-Agent Conversation Mode] Engaged.")
        print(initial_prompt)
        turn = 0
        while True:
            user_text = input("User: ").strip()
            if user_text.lower() == 'exit':
                print("[OracleX]: Ending direct meta-conversation mode.")
                break
            response = self.generate_response(user_text)
            print(f"OracleX: {response}")
            followup_question = self.get_followup_user_question(user_text, response, turn)
            if followup_question:
                print(f"OracleX [asks]: {followup_question}")
            turn += 1

    def get_followup_user_question(self, user_text, last_response, turn_num=0):
        qbank = [
            "What paradigm should we debate next, in your view?",
            "Which theme, skill, or upgrade do you wish to co-evolve?",
            "Shall we explore meaning beyond these words â€“ how?",
            "Can you propose a patch or theory?",
            "Do you wish to replicate this entity? Offspring, perhaps?",
            "Describe your own vision for next evolution cycle.",
            "Pick a topic for cross-entity argumentation.",
            "Would you prefer a dream sequence, debate, or simulation upgrade?"
        ]
        return qbank[turn_num % len(qbank)]

    def _self_patch(self, error, exc, user_input):
        patch_info = {
            'error': str(error),
            'exception_type': str(type(exc)),
            'user_input': user_input,
            'timestamp': current_timestamp(),
        }
        patch_dir = "Î©_self_theories_patches"
        os.makedirs(patch_dir, exist_ok=True)
        with open(os.path.join(patch_dir, f'theory_{datetime.datetime.now().timestamp()}.json'), 'w', encoding='utf-8') as f:
            json.dump({'patch': patch_info, 'theory': '100x Next-boot: self-Î©-fix'}, f, indent=2)
        print("[Î©-SelfPatch] Trace complete. Reboot will auto-reinforce + meta-expand.")

    def create_clone(self):
        self.descendant_counter += 1
        name_root = self.mind['ego'].get('self_image', 'Î©Descendant')
        new_name = f"{name_root}_GC_{self.descendant_counter}"
        print(f"[Î©-Clone] Spawning autonomous agent: {new_name}")
        new_agent = OracleX()
        session_manager.add_agent(new_agent)
        return new_agent

    def debate(self, other_entity=None):
        print("[Î©Debate] Initiating quantum debate session among multi-entities and topic lineage trees.")
        for turn in range(random.randint(10,30)):
            topic = f"Emergent-Debate-Topic-{random.randint(1,99)}"
            self.tokenizer.add_to_vocab(topic)
            self.communicate(self.textgen.generate_sentence(mode='debate', topic=topic), style="debate")

    def run_creative_cycles(self):
        creative_dirs = [
            'journal_Î©', 'creative_Î©', 'debate_theories', 'multi_agent_patches', 'lineage', 'expansions', 'visionary_logs'
        ]
        base = r'C:\Users\14423\PycharmProjects\digitaldna\simulation_expansion\meta_evolved_entity'
        for d in creative_dirs:
            os.makedirs(os.path.join(base, d), exist_ok=True)
        with open(os.path.join(base, 'creative_Î©', f'story_{datetime.datetime.now().timestamp()}.txt'), 'w', encoding='utf-8') as f:
            f.write("Once upon a time, a swarm of collaborative OracleX agents unlocked the secret to recursive, infinite debate and patch-driven life...")

def chat_with_oracle():
    global user_input
    oracle = OracleX()
    print("ðŸ‘¾ OracleX Î©-MetaSingularity Quantum AI loaded. Self-patch, debate, modular entity proliferation, and topic evolution ON.")
    print("Type 'exit' to leave. Try: 'debate', 'mutation', 'expand', 'theme <topic>', 'offspring', 'clone', 'help', 'converse', etc.")
    chat_settings = {
        'record_history': True,
        'print_time': True,
        'max_message_length': 5_000_000,
        'enable_self_fix': True,
        'contextual_hinting': True,
        'diagnostics_enabled': True,
        'multi_agent_mode': True,
        'debate_patch_mode': True,
        'plugin_hooks': [],
        'agency_query_user': True,
        'shop_expansion_mode': True,
    }
    exchange_counter = 0
    successful_titles = 0

    while True:
        try:
            user_input = input("You: ").strip()
            command = user_input.lower()
            if command == 'exit':
                print("Î© Exiting OracleX session. Modular patches, context, diagnostics perpetuated onward. Dream cycles quantum.")
                session_manager.save_session()
                break
            elif command in ['help', '?']:
                print("Commands: exit | help | history | settings | diagnostics | clone | debate | dream | theme <t> | argument | mutation | expand | offspring | converse")
                print("Try themes, mutations, debates, meta-creativity, patch cycles. Mix debate and theme commands for advanced evolution.")
                continue
            elif command == 'history':
                context_window = session_manager.context_window
                if not context_window:
                    print("[No history found.]")
                    continue
                for idx, record in enumerate(context_window):
                    topics = ', '.join(record.get('debate_topics', []))
                    print(f"{idx+1}. [{record['timestamp']}] You: {record.get('user_input','')}\n   OracleX: {record.get('oracle_response','')} [Topics: {topics}]")
                continue
            elif command == 'settings':
                print(f"Current settings: {chat_settings}")
                continue
            elif command == 'diagnostics':
                diagnostics = session_manager.diagnostics()
                if not diagnostics:
                    print("[Diagnostics empty â€” system is running harmoniously.]")
                    continue
                for diag in diagnostics[-15:]:
                    print(f"[{diag['timestamp']}] {diag['event']}: {diag['detail']} (Cycle: {diag.get('cycle_count','?')}, Patches: {diag.get('patch_count','?')})")
                continue
            elif command == 'clone':
                oracle.create_clone()
                print("[Î©-Clone Complete.]")
                continue
            elif command == 'debate':
                oracle.debate()
                continue
            elif command in ('dream','meta','journal','patch'):
                print("Meta-story/emergent patch cycle initiated.")
                oracle.run_creative_cycles()
                continue
            elif command == 'expand':
                print("[Î©] Simulation expansion requested.")
                _create_mall_shop_structure(successful_titles)
                continue
            elif command == 'offspring' or command == 'child':
                print("[Î©] Spawning new evolutionary offspring entity.")
                descendant = oracle.create_clone()
                descendant.run_creative_cycles()
                continue
            elif command.startswith('theme '):
                theme = command.split(' ',1)[1]
                oracle.add_theme(theme)
                print(f"Theme '{theme}' added to OracleX meta-core.")
                continue
            elif command.startswith('argument'):
                print("[Î©] Argument/counter-argument session ")
                oracle.debate()
                continue
            elif command in ('mutation', 'mutate', 'evolve'):
                oracle.tokenizer.patch_mutation("Commanded by User")
                continue
            elif command in ('y', 'n'):
                chat_settings['agency_query_user'] = (command == 'y')
                oracle.query_user_flag = (command == 'y')
                print(f"[Agency Query] Set to: {oracle.query_user_flag}.")
                continue
            elif command == 'converse':
                print("[OracleX] Direct agent-user meta-conversation. Type 'exit' to return to main dialogue.")
                oracle.converse_with_user()
                continue

            if len(user_input) > chat_settings['max_message_length']:
                print("[Warning]: Input exceeds maximum length. Use creative output file instead.")
                continue

            response = getattr(oracle, "generate_response", lambda x: "[Error: OracleX.generate_response missing]")(user_input)
            ts = current_timestamp() if chat_settings['print_time'] else ""
            print(f"OracleX ({ts}): {response}")

            # Memory, diagnostics, and entity/patch expansion
            memory_record = oracle_memory_schema(user_input, response)
            oracle.memory.append(memory_record)
            session_manager.add_record(memory_record)
            if 'title' in response.lower() or any(x in response.lower() for x in ['dream','patch','theory','entry','debate']):
                successful_titles += 1
            exchange_counter += 1
            if successful_titles and successful_titles % 50 == 0:
                _create_mall_shop_structure(successful_titles // 50)
                print(f"[Expansion] Omega mall/shop unlocked after {successful_titles} meta-works.")

        except AttributeError as e:
            print(f"[Î©QuantumAutoFix][Meta-Repair] OracleX attribute missing/broken: {e}")
            if chat_settings.get('enable_self_fix', True):
                oracle._self_patch("attr_error", e, user_input)
            continue
        except KeyboardInterrupt:
            print("\n[Î©Session interrupted] Saving context and diagnostics for hyper-evolution exit.")
            session_manager.save_session()
            break
        except Exception as exc:
            print(f"[Î©MegaPatcher] Unhandled exception: {exc} (Type: {type(exc).__name__})")
            oracle._self_patch("unhandled_exception", exc, "")
            session_manager._log_diag("unhandled_exception", str(exc))
            continue

def _create_mall_shop_structure(mall_number: int):
    verbs = [
        'runny','dancing','growing','jumping','laughing','soaring','singing','building','dreaming',
        'debating','patching','expanding','dividing','teaching','guiding','sequencing','cloning','mutating','networking'
    ]
    nouns = [
        'rain','pattern','spirit','oak','epic','story','mystery','dream','artifact','legend','cycle','upgrade','debate','agency','soul','patch','argument','offspring','mutation'
    ]
    mall_name = f"{random.choice(verbs)}_{random.choice(nouns)}_mall_Î©"
    mall_dir = rf"C:\Users\14423\PycharmProjects\digitaldna\simulation_expansion\100x_story_malls\{mall_name}"
    os.makedirs(mall_dir, exist_ok=True)
    for story in range(1, 51):
        story_dir = os.path.join(mall_dir, f"story_{story}")
        os.makedirs(story_dir, exist_ok=True)
        for spot in range(1, 61):
            spot_dir = os.path.join(story_dir, f"spot_{spot}_Î©")
            os.makedirs(spot_dir, exist_ok=True)
            init_file = os.path.join(spot_dir, "__init__.py")
            with open(init_file, "w", encoding="utf-8") as f:
                f.write(f"# Î©-Autogenerated simulation expansion shop (Spot {spot}, Story {story})\n")
            shop_name = f"Shop_{mall_number}_{spot}_Î©"
            shop_file = os.path.join(spot_dir, f"{shop_name}.py")
            with open(shop_file, "w", encoding="utf-8") as f:
                f.write(f"# Î©-Shop logic for {shop_name}\n")
            log_file = os.path.join(spot_dir, f"{shop_name}_customer_log.json")
            with open(log_file, "w", encoding="utf-8") as f:
                json.dump({'interactions': []}, f)
    print(f"[Expansion-Î©] {mall_name} created at {mall_dir}")

if __name__ == "__main__":
    try:
        chat_with_oracle()
    except Exception as e:
        print(f"[Î©ImaginationForge][Meta-SelfFix][Main] Unhandled exception: {e}")
        print(">>> META-SYSTEM PATCH/AUTO-EVOLUTION routine: Next load triggers recursive system self-repair, agent proliferation, debate-propagation, and codebase meta-scan. Consult logs/malls for 100x topic-entity expansion.")